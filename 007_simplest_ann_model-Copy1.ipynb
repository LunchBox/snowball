{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25476ae5-2ce9-467a-aa52-76d1de00dba8",
   "metadata": {},
   "source": [
    "## Simplest ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10f0bc-84d5-4403-81cd-037b532ab7c4",
   "metadata": {},
   "source": [
    "一樣是最簡單的 ANN model ，一個 input 層，2 個隱藏層，1個輸出層，輸出層只有 1 個node。\n",
    "\n",
    "這個 sample 是在 007 的基礎上，將 input 數據轉為百分比，算是 normalize？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ff1ba-2404-40f7-86b9-15a58c400f49",
   "metadata": {},
   "source": [
    "但不知道為啥 train 一陣子後會變成 nan.. 和 diff 改成 pct_change 有關..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b5a33e-8ce7-45e3-8342-8956d0731f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.rolling_to_list import rolling_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e00c57b-2bdd-4932-a6be-083c6fd641d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare device\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd44d2a-d5b0-4f66-b21b-489d6388d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print up/down in --o--o- format\n",
    "def puts(arr): print(''.join([\"o\" if x > 0 else '-' for x in arr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd3e27a-2bb8-48a0-9174-d38e24e8d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['^SPX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e3c5db-f3a9-4f8d-989f-65afcb0e905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回看過去的窗口\n",
    "rolling_back = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0939a6a-1c96-4d3b-8fb6-427ca09f8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 觀察窗口\n",
    "expect_period = 1 # 5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7288d0-e4d1-490d-b87d-b74478ba3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_friday_5.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ffeff0-fa38-4e31-8192-e8adfa7c99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = \"60d\"\n",
    "interval = \"5m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebaf3cc4-520a-47bd-b46f-ecf85f6f9016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-04 09:30:00-05:00</th>\n",
       "      <td>4564.370117</td>\n",
       "      <td>4566.580078</td>\n",
       "      <td>4558.390137</td>\n",
       "      <td>4566.580078</td>\n",
       "      <td>4566.580078</td>\n",
       "      <td>127454215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-04 09:35:00-05:00</th>\n",
       "      <td>4566.959961</td>\n",
       "      <td>4568.049805</td>\n",
       "      <td>4563.319824</td>\n",
       "      <td>4565.990234</td>\n",
       "      <td>4565.990234</td>\n",
       "      <td>88653884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-04 09:40:00-05:00</th>\n",
       "      <td>4566.009766</td>\n",
       "      <td>4569.209961</td>\n",
       "      <td>4565.479980</td>\n",
       "      <td>4567.479980</td>\n",
       "      <td>4567.479980</td>\n",
       "      <td>82133816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-04 09:45:00-05:00</th>\n",
       "      <td>4567.410156</td>\n",
       "      <td>4570.919922</td>\n",
       "      <td>4567.410156</td>\n",
       "      <td>4569.609863</td>\n",
       "      <td>4569.609863</td>\n",
       "      <td>87963286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-04 09:50:00-05:00</th>\n",
       "      <td>4569.680176</td>\n",
       "      <td>4571.839844</td>\n",
       "      <td>4567.049805</td>\n",
       "      <td>4569.140137</td>\n",
       "      <td>4569.140137</td>\n",
       "      <td>78119822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23 15:35:00-05:00</th>\n",
       "      <td>5090.120117</td>\n",
       "      <td>5093.709961</td>\n",
       "      <td>5089.149902</td>\n",
       "      <td>5092.069824</td>\n",
       "      <td>5092.069824</td>\n",
       "      <td>53058612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23 15:40:00-05:00</th>\n",
       "      <td>5092.060059</td>\n",
       "      <td>5092.810059</td>\n",
       "      <td>5091.040039</td>\n",
       "      <td>5091.040039</td>\n",
       "      <td>5091.040039</td>\n",
       "      <td>57465798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23 15:45:00-05:00</th>\n",
       "      <td>5091.049805</td>\n",
       "      <td>5095.750000</td>\n",
       "      <td>5090.660156</td>\n",
       "      <td>5095.339844</td>\n",
       "      <td>5095.339844</td>\n",
       "      <td>78725870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23 15:50:00-05:00</th>\n",
       "      <td>5095.390137</td>\n",
       "      <td>5097.200195</td>\n",
       "      <td>5093.620117</td>\n",
       "      <td>5094.259766</td>\n",
       "      <td>5094.259766</td>\n",
       "      <td>131331130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23 15:55:00-05:00</th>\n",
       "      <td>5094.299805</td>\n",
       "      <td>5094.399902</td>\n",
       "      <td>5089.310059</td>\n",
       "      <td>5089.310059</td>\n",
       "      <td>5089.310059</td>\n",
       "      <td>197450662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4368 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Datetime                                                                        \n",
       "2023-12-04 09:30:00-05:00  4564.370117  4566.580078  4558.390137  4566.580078   \n",
       "2023-12-04 09:35:00-05:00  4566.959961  4568.049805  4563.319824  4565.990234   \n",
       "2023-12-04 09:40:00-05:00  4566.009766  4569.209961  4565.479980  4567.479980   \n",
       "2023-12-04 09:45:00-05:00  4567.410156  4570.919922  4567.410156  4569.609863   \n",
       "2023-12-04 09:50:00-05:00  4569.680176  4571.839844  4567.049805  4569.140137   \n",
       "...                                ...          ...          ...          ...   \n",
       "2024-02-23 15:35:00-05:00  5090.120117  5093.709961  5089.149902  5092.069824   \n",
       "2024-02-23 15:40:00-05:00  5092.060059  5092.810059  5091.040039  5091.040039   \n",
       "2024-02-23 15:45:00-05:00  5091.049805  5095.750000  5090.660156  5095.339844   \n",
       "2024-02-23 15:50:00-05:00  5095.390137  5097.200195  5093.620117  5094.259766   \n",
       "2024-02-23 15:55:00-05:00  5094.299805  5094.399902  5089.310059  5089.310059   \n",
       "\n",
       "                             Adj Close     Volume  \n",
       "Datetime                                           \n",
       "2023-12-04 09:30:00-05:00  4566.580078  127454215  \n",
       "2023-12-04 09:35:00-05:00  4565.990234   88653884  \n",
       "2023-12-04 09:40:00-05:00  4567.479980   82133816  \n",
       "2023-12-04 09:45:00-05:00  4569.609863   87963286  \n",
       "2023-12-04 09:50:00-05:00  4569.140137   78119822  \n",
       "...                                ...        ...  \n",
       "2024-02-23 15:35:00-05:00  5092.069824   53058612  \n",
       "2024-02-23 15:40:00-05:00  5091.040039   57465798  \n",
       "2024-02-23 15:45:00-05:00  5095.339844   78725870  \n",
       "2024-02-23 15:50:00-05:00  5094.259766  131331130  \n",
       "2024-02-23 15:55:00-05:00  5089.310059  197450662  \n",
       "\n",
       "[4368 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 下載數據，合併成一個 df\n",
    "# if len(tickers) > 1:\n",
    "# \tdfs = yf.download(tickers, period=period, interval=interval, group_by='Ticker')\n",
    "# \tdf_global = pd.concat([dfs[k].add_prefix(k + \"_\") for k in tickers], axis=1)\n",
    "# else:\n",
    "# \tdf_global = yf.download(tickers, period=period, interval=interval).add_prefix(tickers[0] + \"_\")\n",
    "\n",
    "df_global = yf.download(tickers, period=period, interval=interval)\n",
    "df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "732aceee-dbab-48fe-8125-7cc13a0347a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    # 相對於起始位置的改變\n",
    "    diffs = df.pct_change(rolling_back).add_suffix(\"_Diff\")\n",
    "    \n",
    "    # diff to N days ago\n",
    "    diffs_9 = df.pct_change(9).add_suffix(\"_Diff9\")\n",
    "    diffs_26 = df.pct_change(26).add_suffix(\"_Diff26\")\n",
    "    \n",
    "    hist_diffs = pd.concat([df, diffs, diffs_9, diffs_26], axis=1)\n",
    "    \n",
    "    # # 同一個 slot 內相對於 Open 的改變\n",
    "    # slot_diffs = []\n",
    "    # for k in tickers:\n",
    "    #     tg = \"Open\"\n",
    "    #     for fg in [\"Close\", \"High\", \"Low\"]:\n",
    "    #         slot_diff = df[\"%s_%s\" % (k, fg)] - df[\"%s_%s\" % (k, tg)] \n",
    "    #         slot_diff.name = \"%s_%s_%s\" % (k, fg, tg)\n",
    "    #         slot_diffs.append(slot_diff)\n",
    "\n",
    "    # slot_diffs = pd.concat(slot_diffs, axis=1)\n",
    "\n",
    "    slot_diffs = pd.DataFrame()\n",
    "    slot_diffs['Close_Open'] = (df['Close'] - df['Open']) / df['Open']\n",
    "    slot_diffs['High_Open'] = (df['High'] - df['Open']) / df['Open']\n",
    "    slot_diffs['Low_Open'] = (df['Low'] - df['Open']) / df['Open']\n",
    "    \n",
    "    all_diffs = pd.concat([hist_diffs, slot_diffs], axis=1).fillna(0)\n",
    "    # print(all_diffs.columns)\n",
    "    \n",
    "    \n",
    "    # 補充一些技術指標\n",
    "    extra_series = []\n",
    "    for k in all_diffs.columns:\n",
    "        for i in [9, 17]:\n",
    "            sma_tg = all_diffs[k].rolling(i).mean()\n",
    "            cross = (all_diffs[k] - sma_tg) / sma_tg\n",
    "            cross.name = \"%s_SMA_c%d\" % (k, i)\n",
    "            extra_series.append(cross)\n",
    "        \n",
    "        ema12 = all_diffs[k].ewm(span=12, adjust=False).mean()\n",
    "        for i in [26]:\n",
    "            ema_tg = all_diffs[k].ewm(span=i, adjust=False).mean()\n",
    "            macd = (ema12 - ema_tg) / ema_tg\n",
    "            macd.name = \"%s_MACD_12cross%d\" % (k, i)\n",
    "            extra_series.append(macd)\n",
    "        \n",
    "            macd_signal = macd.ewm(span=9, adjust=False).mean()\n",
    "            macd_signal.name = \"%s_signal\" % macd.name\n",
    "            extra_series.append(macd_signal)\n",
    "    \n",
    "    extra_series = pd.concat(extra_series, axis=1)\n",
    "    \n",
    "    combine = pd.concat([all_diffs, extra_series], axis=1).fillna(0)\n",
    "    # print(combine)\n",
    "\n",
    "    # 把過去 N 天的數據拉成一行\n",
    "    return rolling_to_list(combine, rolling_back)\n",
    "    \n",
    "    # # 把過去 N 天的數據拉成一行\n",
    "    # rolling_back_series = []\n",
    "    # for k in combine.columns:\n",
    "    #     # series = pd.Series([w.tolist() for w in combine[k].rolling(rolling_back)], name=k)\n",
    "    #     sd = pd.DataFrame([w.values for w in combine[k].rolling(rolling_back)])\n",
    "    #     rolling_back_series.append(sd)\n",
    "    \n",
    "    # container = pd.concat(rolling_back_series, axis=1).fillna(0)\n",
    "    # display(container)\n",
    "    # return container.values\n",
    "    \n",
    "    # 每一行合併成一個 list\n",
    "    # return container.apply(lambda row: sum(row, []), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa0a5733-8e2b-47a5-8d7a-107b882772e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.MSELoss()\n",
    "# loss_function = torch.nn.L1Loss()\n",
    "# loss_function = torch.nn.BCELoss()\n",
    "\n",
    "def prepare_model(input_size):\n",
    "    # if os.path.isfile(model_path):\n",
    "    #     model = torch.load(model_path).to(device)\n",
    "    #     return model\n",
    "    \n",
    "    sigmoid_layer = torch.nn.Sigmoid()\n",
    "    \n",
    "    layers = []\n",
    "    layers.append(torch.nn.Linear(input_size, 400))\n",
    "    layers.append(sigmoid_layer)\n",
    "    layers.append(torch.nn.Linear(400, 200))\n",
    "    layers.append(sigmoid_layer)\n",
    "    layers.append(torch.nn.Linear(200, 1))\n",
    "    # layers.append(sigmoid_layer)\n",
    "    \n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "    # model = nn_model.MLPClassifier(nn_data.input_size).to(nn_data.device)\n",
    "\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "    torch.save(model, model_path)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e5a97f-b3ad-46fc-a9d9-6937bd7e4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, train_set, expect_set, report_period=100):\n",
    "    for epoch in range(epochs):\n",
    "        prediction = model(train_set)\n",
    "        \n",
    "        loss = loss_function(prediction, expect_set)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if epoch % report_period == 0:\n",
    "            print(epoch, loss.item())\n",
    "            \n",
    "    # save the model\n",
    "    torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ec463d-74be-4a7f-bc57-0468436dc5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prepare_data(df_global)\n",
    "\n",
    "# there is no actual data for the last set of training data\n",
    "train_data = train_data[:-expect_period] \n",
    "train_data = train_data[rolling_back:]\n",
    "# expect_set = torch.Tensor(train_data.values).to(device)\n",
    "\n",
    "# prepare all actual result\n",
    "actual = df_global['Close'].pct_change(expect_period) * 500\n",
    "# 往前移動\n",
    "actual = actual.shift(-expect_period)[:-expect_period]\n",
    "actual = actual.shift(-rolling_back)[:-rolling_back]\n",
    "\n",
    "actual = actual.reset_index(drop=True)\n",
    "actual = actual.values.reshape(-1,1)\n",
    "# expect_set = torch.Tensor(actual).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfacc7c7-4f82-4f36-b51a-828ea4a17b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = 2880\n",
    "# model, optimizer  = prepare_model(input_size)\n",
    "\n",
    "# display(pd.DataFrame(train_data[:296]))\n",
    "\n",
    "# t1 = torch.Tensor(train_data[:296]).to(device)\n",
    "# t2 = torch.Tensor(actual[:296]).to(device)\n",
    "\n",
    "# print(t1.shape)\n",
    "# print(t2.shape)\n",
    "\n",
    "# # train(1000, t1, t2, 100)\n",
    "# r1 = model(torch.Tensor(train_data[:296]).to(device))\n",
    "\n",
    "# loss_function(r1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5ccd1ba-1911-4c9e-b04b-80814c3aadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用前 5 日的數據做相對多次訓練， e.g 5000 次\n",
    "first_batch_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2401991c-af5c-4f88-82a2-82491958b489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4118, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df007 = df_global[first_batch_size:]\n",
    "\n",
    "df007.to_csv(\"df007.csv\")\n",
    "\n",
    "df007.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced81fb8-175a-4042-8028-3cccc6b4f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- loop 58 / 3997 --\n",
      "-- check prediction --\n",
      "Error :  nan\n",
      "tensor([[nan]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "[[0.11173606]]\n",
      "0 nan\n",
      "100 nan\n",
      "200 nan\n",
      "300 nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m expect_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(actual[i:first_batch_size \u001b[38;5;241m+\u001b[39m i])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpect_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- run time: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, train_set, expect_set, report_period)\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m----> 8\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m report_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(epoch, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/workspace/snowball/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    372\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 373\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# call optimizer step pre hooks\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pre_hook \u001b[38;5;129;01min\u001b[39;00m chain(_global_optimizer_pre_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_pre_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    376\u001b[0m         result \u001b[38;5;241m=\u001b[39m pre_hook(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n",
      "File \u001b[0;32m~/workspace/snowball/venv/lib/python3.10/site-packages/torch/autograd/profiler.py:622\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m--> 622\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_exit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[0;32m~/workspace/snowball/venv/lib/python3.10/site-packages/torch/_ops.py:512\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<OpOverload(op=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, overload=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overloadname\n\u001b[1;32m    510\u001b[0m     )\n\u001b[0;32m--> 512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = []\n",
    "hist_file = \"hist007.csv\"\n",
    "\n",
    "# first batch\n",
    "train_set = torch.Tensor(train_data[:first_batch_size]).to(device)\n",
    "expect_set = torch.Tensor(actual[:first_batch_size]).to(device)\n",
    "\n",
    "print('-- train set shape: --')\n",
    "print(train_set.shape)\n",
    "print('-- expect set shape: --')\n",
    "print(expect_set.shape)\n",
    "\n",
    "input_size = train_set.shape[1]\n",
    "model, optimizer  = prepare_model(input_size)\n",
    "\n",
    "train(10000, train_set, expect_set, 500)\n",
    "\n",
    "rest = len(train_data) - first_batch_size\n",
    "for i in range(rest):\n",
    "    clear_output(wait=True)\n",
    "    print(\"-- loop %d / %d --\" % (i, rest))\n",
    "\n",
    "    print(\"-- check prediction --\")\n",
    "    predictions = model(train_set)\n",
    "    # print(\"Predictions : \\n\", predictions.detach().cpu())\n",
    "    \n",
    "    error = loss_function(predictions, expect_set)\n",
    "    print(\"Error : \", error.detach().cpu().numpy())\n",
    "\n",
    "    next_idx = first_batch_size + i\n",
    "    last_set = torch.Tensor(train_data[next_idx:next_idx + 1]).to(device)\n",
    "    last_exp = actual[next_idx:next_idx + 1]\n",
    "    \n",
    "    print(model(last_set))\n",
    "    print(last_exp)\n",
    "    hist.append([model(last_set).tolist()[0][0], last_exp[0][0]])\n",
    "    pd.DataFrame(hist).to_csv(hist_file, index=False)  \n",
    "\n",
    "    train_set = torch.Tensor(train_data[i:first_batch_size + i]).to(device)\n",
    "    expect_set = torch.Tensor(actual[i:first_batch_size + i]).to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    train(800, train_set, expect_set)\n",
    "    print(\"--- run time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9df165-94c2-4d6c-a7d8-7334aff61a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1Loss = torch.nn.L1Loss()\n",
    "MSELoss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339ebbf-b217-4a52-82b8-6c29ec63a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check hist diffs\n",
    "hist = pd.read_csv(hist_file)\n",
    "\n",
    "model_result = torch.Tensor(hist.iloc[:, 0])\n",
    "actual_result = torch.Tensor(hist.iloc[:, 1])\n",
    "\n",
    "print(L1Loss(model_result, actual_result))\n",
    "print(MSELoss(model_result, actual_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4a3f3-ba44-4306-b3f7-d874aab75638",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1loss_hist = []\n",
    "mseloss_hist = []\n",
    "\n",
    "for i in range(hist.shape[0]):\n",
    "    ds = hist[:i]\n",
    "    model_result = torch.Tensor(ds.iloc[:, 0])\n",
    "    actual_result = torch.Tensor(ds.iloc[:, 1])\n",
    "    l1loss_hist.append(L1Loss(model_result, actual_result))\n",
    "    mseloss_hist.append(MSELoss(model_result, actual_result))\n",
    "\n",
    "plt.plot(l1loss_hist, label=\"l1loss\")\n",
    "plt.plot(mseloss_hist, label=\"mseloss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b9ecc-1b2c-423c-9343-dd4bdc37bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.iloc[:, 0] - hist.iloc[:, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
